"""Run `kipoi predict` for multiple models
"""
import kipoi

# --------------------------------------------
# Config
fasta_file = 'input/hg19.chr22.fa'

# which bed files to run
intervals = ['random', 'enhancer-regions']

# get all DeepBind models in trained on human ChIP-seq
df = kipoi.list_models()
deepbind_models = df.model[df.model.str.match("DeepBind/Homo_sapiens/TF/.*_ChIP-seq.*")].tolist()
assert len(deepbind_models) == 137

# which models to use
models = ['Basset'] + deepbind_models[:5]  # + ['DeepSEA/predict']

# You can also use the following two, but you have to install the environment
# `kipoi env create shared/envs/kipoi-py3-keras1.2`
# ['CpGenie/merged', 'DeepCpg_DNA/Hou2016_mESC_dna']

# output file formats
file_formats = ['tsv', 'h5']
# --------------------------------------------

rule all:
    input:
        expand('output/{model}/{interval}.{ext}',
               model=models,
               interval=intervals,
               ext=file_formats)

# Main rule
rule predict:
    """Generic rule for running model prediction for Kipoi models
    that take as input `intervals_file` and `fasta_file`
    """
    input:
        intervals_file = "input/{interval}.hg19.chr22.bed.gz",
        fasta_file = fasta_file
    output:
        predictions = expand("output/{{model}}/{{interval}}.{ext}", ext=file_formats)
    params:
        workers = 10,  # number of workers,
        batch_size = 32
    shell:
        """
        kipoi_cmd=$(kipoi env get_cli {wildcards.model})

        $kipoi_cmd predict \
          {wildcards.model} \
          --dataloader_args='{{"intervals_file": "{input.intervals_file}",
                              "fasta_file": "{input.fasta_file}"}}' \
          -n {params.workers} \
          --batch_size={params.batch_size} \
          -o {output.predictions}
        """

rule unzip:
    input:
        fa_gz = fasta_file + ".gz"
    output:
        fa = fasta_file
    shell:
        "zcat {input.fa_gz} > {output.fa}"
        
